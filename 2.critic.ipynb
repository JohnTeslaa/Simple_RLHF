{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ls -al /content/drive/MyDrive/Simple_RLHF/model/actor\n"
      ],
      "metadata": {
        "id": "HMEGZ_zeqa1l",
        "outputId": "4e8c676f-899e-438c-f8ba-7e078d9b2a11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HMEGZ_zeqa1l",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 5139760\n",
            "-rw------- 1 root root        749 Mar  9 01:55 config.json\n",
            "-rw------- 1 root root        132 Mar  9 01:55 generation_config.json\n",
            "-rw------- 1 root root 4994509120 Mar  9 01:55 model-00001-of-00002.safetensors\n",
            "-rw------- 1 root root  268568856 Mar  9 01:56 model-00002-of-00002.safetensors\n",
            "-rw------- 1 root root      33832 Mar  9 01:56 model.safetensors.index.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "01f23638",
      "metadata": {
        "id": "01f23638",
        "outputId": "7399223f-6b2b-4487-d683-a2f2adec69f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   0, 9178,   32,    2]), tensor([1, 1, 1, 1]), '<s>how are</s>')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Simple_RLHF')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "from util import TokenizerUtil\n",
        "\n",
        "tokenizer = TokenizerUtil()\n",
        "\n",
        "input_ids, attention_mask = tokenizer.encode('how are you', max_length=4)\n",
        "\n",
        "input_ids, attention_mask, tokenizer.decode(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "85e428b1",
      "metadata": {
        "id": "85e428b1",
        "outputId": "a7e5ea8e-2bb5-4917-9e25-60b092069e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "40469780c64743ee996cccffb17ad650",
            "3cf16f73b6804b37be39fcdbc0b28dc6",
            "3727f13395da48448c037ac03ca1e1d5",
            "3470de8f73304fcb8d4d521e3081c263",
            "2e0a5d8d477c474f86ed8fb99f8272a5",
            "ed176bf51d4f4ec7ab7c5be3d0f69b36",
            "2559a3cd7b6e48ffbd0884d7c22800ff",
            "7ef39fe279f74b379c3e94124dd3e2f6",
            "a9bc2e5372fb4daa839337ecd8aff778",
            "f958a75971e049929227980d540ba8eb",
            "1d8981e5c31e466a992c28b0c8715e4b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40469780c64743ee996cccffb17ad650"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,\n",
              " {'input_ids': tensor([[    0, 33837,    35,  ...,     1,     1,     1],\n",
              "          [    0, 33837,    35,  ...,     1,     1,     1]]),\n",
              "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]])})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('json', data_files='/content/drive/MyDrive/Simple_RLHF/dataset/train.json', split='train')\n",
        "\n",
        "#2,4,4切分,取第1部分\n",
        "dataset = dataset.select(range(15000, 15050))\n",
        "\n",
        "\n",
        "def f(data):\n",
        "    #区分两种生成结果\n",
        "    chosen = data['prompt'] + data['chosen'].swapcase()\n",
        "    rejected = data['prompt'] + data['chosen']\n",
        "\n",
        "    chosen_input_ids, chosen_attention_mask = tokenizer.encode(chosen)\n",
        "    rejected_input_ids, rejected_attention_mask = tokenizer.encode(rejected)\n",
        "\n",
        "    return {\n",
        "        'chosen_input_ids': chosen_input_ids,\n",
        "        'chosen_attention_mask': chosen_attention_mask,\n",
        "        'rejected_input_ids': rejected_input_ids,\n",
        "        'rejected_attention_mask': rejected_attention_mask\n",
        "    }\n",
        "\n",
        "\n",
        "dataset = dataset.map(f)\n",
        "dataset.set_format('torch')\n",
        "\n",
        "\n",
        "def f(data):\n",
        "    chosen_input_ids = [i['chosen_input_ids'] for i in data]\n",
        "    chosen_attention_mask = [i['chosen_attention_mask'] for i in data]\n",
        "    rejected_input_ids = [i['rejected_input_ids'] for i in data]\n",
        "    rejected_attention_mask = [i['rejected_attention_mask'] for i in data]\n",
        "\n",
        "    input_ids = torch.stack(chosen_input_ids + rejected_input_ids, dim=0)\n",
        "    attention_mask = torch.stack(chosen_attention_mask +\n",
        "                                 rejected_attention_mask,\n",
        "                                 dim=0)\n",
        "\n",
        "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset,\n",
        "                                     collate_fn=f,\n",
        "                                     batch_size=1,\n",
        "                                     shuffle=True,\n",
        "                                     drop_last=True)\n",
        "\n",
        "len(loader), next(iter(loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dfa4c50a",
      "metadata": {
        "id": "dfa4c50a",
        "outputId": "c04974d2-080a-421c-a393-3f72aa7df2c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'count_require': 3.31196928, 'count_all': 3.31196928, 'ratio': 1.0}\n"
          ]
        }
      ],
      "source": [
        "from costom_lora import count_params\n",
        "\n",
        "\n",
        "class CriticModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        from transformers import AutoModel\n",
        "        self.rwtransformer = AutoModel.from_pretrained('facebook/opt-350m',\n",
        "                                                       dropout=0.0)\n",
        "\n",
        "        self.v_head = torch.nn.Linear(512, 1, bias=False)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        value = self.rwtransformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask).last_hidden_state\n",
        "        value = self.v_head(value).squeeze(-1)\n",
        "\n",
        "        loss_sum = 0.0\n",
        "        value_chosen_sum = 0.0\n",
        "        value_rejected_sum = 0.0\n",
        "        for input_ids_chosen, input_ids_rejected, value_chosen, value_rejected in zip(\n",
        "                input_ids[:1], input_ids[1:], value[:1], value[1:]):\n",
        "\n",
        "            #找出每条回答中的起止索引\n",
        "            start = (\n",
        "                input_ids_chosen == input_ids_rejected).tolist().index(False)\n",
        "\n",
        "            end_chosen = input_ids_chosen.tolist().index(\n",
        "                tokenizer.eos_token_id) + 1\n",
        "            end_rejected = input_ids_rejected.tolist().index(\n",
        "                tokenizer.eos_token_id) + 1\n",
        "            end = max(end_chosen, end_rejected)\n",
        "\n",
        "            value_chosen = value_chosen[start:end]\n",
        "            value_rejected = value_rejected[start:end]\n",
        "\n",
        "            loss = value_chosen - value_rejected\n",
        "            loss = -torch.nn.functional.logsigmoid(loss).mean()\n",
        "\n",
        "            loss_sum += loss\n",
        "            value_chosen_sum += value_chosen.mean().item()\n",
        "            value_rejected_sum += value_rejected.mean().item()\n",
        "\n",
        "        return loss_sum / 1, value_chosen_sum, value_rejected_sum\n",
        "\n",
        "\n",
        "model_critic = CriticModel()\n",
        "\n",
        "count_params(model_critic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "adb14bab",
      "metadata": {
        "id": "adb14bab",
        "outputId": "658872eb-9fe0-4c0c-edf8-9ad3972c719c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CriticModel(\n",
              "  (rwtransformer): OPTModel(\n",
              "    (decoder): OPTDecoder(\n",
              "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
              "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
              "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
              "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
              "      (layers): ModuleList(\n",
              "        (0-23): 24 x OPTDecoderLayer(\n",
              "          (self_attn): OPTSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (v_head): Linear(in_features=512, out_features=1, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from transformers import get_scheduler\n",
        "from accelerate import Accelerator\n",
        "\n",
        "\n",
        "def f():\n",
        "    params_decay = []\n",
        "    params = []\n",
        "    for name, param in model_critic.named_parameters():\n",
        "        if 'bias' in name or 'norm.weight' in name:\n",
        "            params.append(param)\n",
        "            continue\n",
        "        params_decay.append(param)\n",
        "\n",
        "    return [{\n",
        "        'params': params_decay,\n",
        "        'weight_decay': 0.1\n",
        "    }, {\n",
        "        'params': params,\n",
        "        'weight_decay': 0.0\n",
        "    }]\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(f(), lr=5e-5, betas=(0.9, 0.95))\n",
        "\n",
        "scheduler = get_scheduler(name='cosine',\n",
        "                          optimizer=optimizer,\n",
        "                          num_warmup_steps=0,\n",
        "                          num_training_steps=500)\n",
        "\n",
        "accelerator = Accelerator(gradient_accumulation_steps=16,\n",
        "                          mixed_precision='fp16')\n",
        "\n",
        "model_critic, loader, optimizer, scheduler = accelerator.prepare(\n",
        "    model_critic, loader, optimizer, scheduler)\n",
        "\n",
        "model_critic.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7838daa6",
      "metadata": {
        "scrolled": false,
        "id": "7838daa6",
        "outputId": "fc66ab44-0948-4b61-9ca8-ff7674650e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i, data in enumerate(loader):\n",
        "    print(i)\n",
        "    with accelerator.accumulate(model_critic):\n",
        "        loss, value_chosen_sum, value_rejected_sum = model_critic(**data)\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        if accelerator.sync_gradients:\n",
        "            accelerator.clip_grad_norm_(model_critic.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        print(i, len(loader), loss.item(), lr, value_chosen_sum,\n",
        "              value_rejected_sum)\n",
        "\n",
        "    if i == 2000:\n",
        "        break\n",
        "\n",
        "torch.save(model_critic.to('cpu'), '/content/drive/MyDrive/Simple_RLHF/model/critic')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al /content/drive/MyDrive/Simple_RLHF/model/"
      ],
      "metadata": {
        "id": "c8ueDiUDG3Wk",
        "outputId": "6475497b-3369-4cc1-d100-a21231d74559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "c8ueDiUDG3Wk",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1293911\n",
            "drwx------ 2 root root       4096 Mar  9 01:55 actor\n",
            "-rw------- 1 root root 1324960543 Mar  9 13:16 critic\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:cuda117]",
      "language": "python",
      "name": "conda-env-cuda117-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40469780c64743ee996cccffb17ad650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cf16f73b6804b37be39fcdbc0b28dc6",
              "IPY_MODEL_3727f13395da48448c037ac03ca1e1d5",
              "IPY_MODEL_3470de8f73304fcb8d4d521e3081c263"
            ],
            "layout": "IPY_MODEL_2e0a5d8d477c474f86ed8fb99f8272a5"
          }
        },
        "3cf16f73b6804b37be39fcdbc0b28dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed176bf51d4f4ec7ab7c5be3d0f69b36",
            "placeholder": "​",
            "style": "IPY_MODEL_2559a3cd7b6e48ffbd0884d7c22800ff",
            "value": "Map: 100%"
          }
        },
        "3727f13395da48448c037ac03ca1e1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef39fe279f74b379c3e94124dd3e2f6",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9bc2e5372fb4daa839337ecd8aff778",
            "value": 50
          }
        },
        "3470de8f73304fcb8d4d521e3081c263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f958a75971e049929227980d540ba8eb",
            "placeholder": "​",
            "style": "IPY_MODEL_1d8981e5c31e466a992c28b0c8715e4b",
            "value": " 50/50 [00:00&lt;00:00, 536.47 examples/s]"
          }
        },
        "2e0a5d8d477c474f86ed8fb99f8272a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed176bf51d4f4ec7ab7c5be3d0f69b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2559a3cd7b6e48ffbd0884d7c22800ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ef39fe279f74b379c3e94124dd3e2f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bc2e5372fb4daa839337ecd8aff778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f958a75971e049929227980d540ba8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8981e5c31e466a992c28b0c8715e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}